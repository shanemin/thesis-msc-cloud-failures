{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob as glob\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil.parser as dparser\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/media/shane/cloud-availability-sacheen-2020-05-11/downdetector' # one directory\n",
    "# root_dir = '/media/shane/cloud-availability-sacheen-2020-05-11/downdetector/2017/201711' # subset of above\n",
    "root_dir = '/media/shane/cloud-availability-sacheen-2020-05-11/downdetector*' # all directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_data(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    result = []\n",
    "    \n",
    "    timestamp = soup.find('meta', attrs={'name':'generated'})\n",
    "    result.append(timestamp.get('content'))\n",
    "    \n",
    "    # status of the service in last 24hrs (no problems, possible problems, problems)\n",
    "    try:\n",
    "        status = soup.find('div', {'class' : re.compile('alert *')})\n",
    "        result.append(status.get('class')[1])\n",
    "    except:\n",
    "        result.append('')\n",
    "    \n",
    "#     # time since problems started (empty unless problems are ongoing)\n",
    "#     for problems_since in soup.find_all(\"div\", {\"class\": \"event\"}):\n",
    "#         try:\n",
    "#             status = ' '.join(problems_since.text.split())\n",
    "#             date = str(dparser.parse(status, fuzzy=True))\n",
    "#             result.append([date.split()[0].split('-')[1:], date.split()[1]])\n",
    "#         except:\n",
    "#             # some months are apparently out of range\n",
    "#             result.append('')\n",
    "    \n",
    "#     # TECHNICAL DEBT: problems_since is not appended if tag does not exist in the html_doc\n",
    "#     if len(result) != 5:\n",
    "#         result.append('')\n",
    "    \n",
    "#     # most reported problems at this time\n",
    "#     mrp = []\n",
    "#     for most_reported in soup.find_all(\"li\"):\n",
    "#         if '%' in most_reported.text:\n",
    "#             mrp.append(' '.join(most_reported.text.split()))\n",
    "#     result.append(mrp)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    source = file.split('/')[4]\n",
    "    archive = ZipFile(file, 'r')\n",
    "    namelist = archive.namelist()\n",
    "    ret = []\n",
    "    for item in namelist:\n",
    "        if 'html' in item:\n",
    "            html = archive.read(item)\n",
    "            service = item.split('/')[1].split('.')[0]\n",
    "            ts = item.split('/')[0]\n",
    "            data = extract_html_data(html)\n",
    "            data.insert(0, ts)\n",
    "            data.insert(0, service)\n",
    "            data.insert(0, source)\n",
    "            ret.append(data)\n",
    "    archive.close()\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072.3796997070312\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(root_dir + '/**/*.zip', recursive=True)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "start_time = time.time()\n",
    "results = pool.map(read_file, [file for file in files])\n",
    "pool.close()\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for outer in results:\n",
    "    for inner in outer:\n",
    "        res.append(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>service</th>\n",
       "      <th>timestamp_dir</th>\n",
       "      <th>timestamp_site</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>downdetector-deu-germany</td>\n",
       "      <td>spotify</td>\n",
       "      <td>20171121T190001</td>\n",
       "      <td>2017-11-21T20:00:45.027659+01:00</td>\n",
       "      <td>alert-danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>downdetector-deu-germany</td>\n",
       "      <td>reddit</td>\n",
       "      <td>20171121T190001</td>\n",
       "      <td>2017-11-21T20:01:17.940977+01:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>downdetector-deu-germany</td>\n",
       "      <td>youtube</td>\n",
       "      <td>20171121T190001</td>\n",
       "      <td>2017-11-21T20:00:19.627327+01:00</td>\n",
       "      <td>alert-warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>downdetector-deu-germany</td>\n",
       "      <td>zynga</td>\n",
       "      <td>20171121T190001</td>\n",
       "      <td>2017-11-21T20:01:13.231012+01:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>downdetector-deu-germany</td>\n",
       "      <td>airbnb</td>\n",
       "      <td>20171121T190001</td>\n",
       "      <td>2017-11-21T20:01:51.711265+01:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323703</th>\n",
       "      <td>downdetector-che-switzerland</td>\n",
       "      <td>spotify</td>\n",
       "      <td>20180911T110001</td>\n",
       "      <td>2018-09-11T13:01:23.194705+02:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323704</th>\n",
       "      <td>downdetector-che-switzerland</td>\n",
       "      <td>youtube</td>\n",
       "      <td>20180911T110001</td>\n",
       "      <td>2018-09-11T13:01:24.013593+02:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323705</th>\n",
       "      <td>downdetector-che-switzerland</td>\n",
       "      <td>netflix</td>\n",
       "      <td>20180911T110001</td>\n",
       "      <td>2018-09-11T13:01:21.620402+02:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323706</th>\n",
       "      <td>downdetector-che-switzerland</td>\n",
       "      <td>snapchat</td>\n",
       "      <td>20180911T110001</td>\n",
       "      <td>2018-09-11T13:01:22.503138+02:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323707</th>\n",
       "      <td>downdetector-che-switzerland</td>\n",
       "      <td>netflix</td>\n",
       "      <td>20180307T000001</td>\n",
       "      <td>2018-03-07T01:00:27.839313+01:00</td>\n",
       "      <td>alert-success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323708 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source   service    timestamp_dir  \\\n",
       "0           downdetector-deu-germany   spotify  20171121T190001   \n",
       "1           downdetector-deu-germany    reddit  20171121T190001   \n",
       "2           downdetector-deu-germany   youtube  20171121T190001   \n",
       "3           downdetector-deu-germany     zynga  20171121T190001   \n",
       "4           downdetector-deu-germany    airbnb  20171121T190001   \n",
       "...                              ...       ...              ...   \n",
       "323703  downdetector-che-switzerland   spotify  20180911T110001   \n",
       "323704  downdetector-che-switzerland   youtube  20180911T110001   \n",
       "323705  downdetector-che-switzerland   netflix  20180911T110001   \n",
       "323706  downdetector-che-switzerland  snapchat  20180911T110001   \n",
       "323707  downdetector-che-switzerland   netflix  20180307T000001   \n",
       "\n",
       "                          timestamp_site         status  \n",
       "0       2017-11-21T20:00:45.027659+01:00   alert-danger  \n",
       "1       2017-11-21T20:01:17.940977+01:00  alert-success  \n",
       "2       2017-11-21T20:00:19.627327+01:00  alert-warning  \n",
       "3       2017-11-21T20:01:13.231012+01:00  alert-success  \n",
       "4       2017-11-21T20:01:51.711265+01:00  alert-success  \n",
       "...                                  ...            ...  \n",
       "323703  2018-09-11T13:01:23.194705+02:00  alert-success  \n",
       "323704  2018-09-11T13:01:24.013593+02:00  alert-success  \n",
       "323705  2018-09-11T13:01:21.620402+02:00  alert-success  \n",
       "323706  2018-09-11T13:01:22.503138+02:00  alert-success  \n",
       "323707  2018-03-07T01:00:27.839313+01:00  alert-success  \n",
       "\n",
       "[323708 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['source','service','timestamp_dir','timestamp_site','status']\n",
    "df = pd.DataFrame(res, columns=column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'/home/shane/Documents/thesis/output/parsed/final/downdetector_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
